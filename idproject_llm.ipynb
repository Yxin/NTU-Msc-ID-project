{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFWpuMXq0O6BfVfonAkAlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yxin/NTU-Msc-ID-project/blob/main/idproject_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up tools to process pcap"
      ],
      "metadata": {
        "id": "3cKs3vTOwyUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy"
      ],
      "metadata": {
        "id": "03psSV4B0rLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract relevant data from pcap into csv (testing and analysing)"
      ],
      "metadata": {
        "id": "KsaIOgPAw5we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import *\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "pcap_file = './sample5.pcap'\n",
        "packets = rdpcap(pcap_file)\n",
        "\n",
        "headers = [\n",
        "    'timestamp', 'ip_src', 'destination_ip',\n",
        "    'source_port',\n",
        "    'destination_port', 'packet_size',\n",
        "    'dns_query_name', 'dns_query_type',\n",
        "    'dns_transaction_id', 'dns_respond_code'\n",
        "]\n",
        "\n",
        "with open('raw_network_data.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file, delimiter=',')\n",
        "    writer.writerow(headers)\n",
        "\n",
        "    row = []\n",
        "    for packet in packets:\n",
        "      if UDP not in packet:\n",
        "            continue\n",
        "      timestamp = datetime.fromtimestamp(int(packet.time))\n",
        "      source_ip= packet[IP].src\n",
        "      destination_ip= packet[IP].dst\n",
        "      source_port = packet[UDP].sport\n",
        "      destination_port = packet[UDP].dport\n",
        "      packet_size = len(packet[UDP].payload)\n",
        "      if packet.haslayer(DNS):\n",
        "        query_name = packet[DNS].qd.qname\n",
        "        query_type = packet[DNS].qd.qtype\n",
        "        transaction_id = packet[DNS].id\n",
        "        respond_code = packet[DNS].rcode\n",
        "    #  pkt_smry = packet.summary() # does not seems to be that useful\n",
        "      row.append([timestamp, source_ip, destination_ip,\n",
        "                  source_port,\n",
        "                destination_port, packet_size,\n",
        "                query_name,query_type, transaction_id, respond_code\n",
        "                ])\n",
        "    # write to CSV for verification\n",
        "    writer.writerows(row)\n",
        "\n",
        "#print(row[0])\n",
        "print(len(row))"
      ],
      "metadata": {
        "id": "mYVUtynazNO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Pandas tool for analystics\n",
        "\n"
      ],
      "metadata": {
        "id": "TuaHCK8Ico33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "MqrLL6pwIz2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feed the extracted data into dataframe"
      ],
      "metadata": {
        "id": "WJ_b5sMxdL-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(row, columns=headers)\n",
        "#print(df)\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "bv6VP34eJDYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert dataframe into readable format"
      ],
      "metadata": {
        "id": "A7cOwH2wdxCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert dataframe into LLM readable format\n",
        "def convert_to_concise_format(row):\n",
        "    #return f\"{row['timestamp']} Src: {row['ip_src']}, Dst: {row['destination_ip']}, Dst_Port: {row['destination_port']}, Query: {row['dns_query_name']}, Type: {row['dns_query_type']}, Code: {row['dns_respond_code']}\"\n",
        "    return f\"{row['timestamp']} Src: {row['ip_src']}:{row['source_port']}, Dst: {row['destination_ip']}:{row['destination_port']}, Query: {row['dns_query_name']}, Type: {row['dns_query_type']}, Code: {row['dns_respond_code']}\"\n",
        "\n",
        "# Apply the function iteratively\n",
        "formatted_rows = [convert_to_concise_format(row) for _, row in df.iterrows()]\n",
        "\n",
        "# Add line break hopefully that helps\n",
        "#formatted_text = \"\\n\".join(formatted_rows)\n",
        "\n",
        "# Print the entries to verify\n",
        "print(formatted_rows[0])"
      ],
      "metadata": {
        "id": "2exDfBJcJk9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure HF_TOKEN with secret token\n",
        "\n",
        "https://huggingface.co/docs/hub/en/security-tokens"
      ],
      "metadata": {
        "id": "J_akpGNPSpQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "HmxesyxSSrrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install up LLM packages"
      ],
      "metadata": {
        "id": "vzuFgmhkwq9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers accelerate optimum\n",
        "!pip3 install autoawq"
      ],
      "metadata": {
        "id": "oJ3ZnkiJwpuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n",
        "!pip show accelerate\n",
        "!pip show optimum\n",
        "!pip show autoawq"
      ],
      "metadata": {
        "id": "b1FMq7Uy73DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run processed data through LLM with designed prompts"
      ],
      "metadata": {
        "id": "mnrAXjagxpX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tokenizer and automodel\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# setup model name from hugging face\n",
        "device = \"cuda\"\n",
        "#model = \"mistralai/Mistral-7B-v0.1\"\n",
        "#model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "model = \"TheBloke/Mistral-7B-OpenOrca-AWQ\"\n",
        "#model = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model, device_map=device) # device map is for parallelism across multiple gpu\n",
        "model = AutoModelForCausalLM.from_pretrained(model)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "y6UDdofqx0V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test prompting"
      ],
      "metadata": {
        "id": "jcZ-QnIHSMwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test prompting\n",
        "initial_prompt = \"You are a network admin reviewing logs to identify hacking activity in the log\"\n",
        "\n",
        "# Dynamic row of logs retrieval\n",
        "log_text =\"\"\n",
        "for row in formatted_rows[:75]:\n",
        "    log_text += row + \" \"\n",
        "\n",
        "#initial_prompt += log_text\n",
        "initial_prompt += \" 2020-10-23 08:37:05 Src: 10.0.2.4, Dst: 10.0.2.1, Dst_Port: 53, Type: 12, Query: b'15.3.0.10.in-addr.arpa.', Code: 0\"\n",
        "\n",
        "initial_prompt += \"\\nQuestion:Analyse this log entries, What activity is happening? Explain your decision.\"\n",
        "\n",
        "initial_model_inputs = tokenizer([initial_prompt], return_tensors=\"pt\").to(device)\n",
        "initial_model_outputs = model.generate(**initial_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "initial_response = tokenizer.batch_decode(initial_model_outputs)[0]\n",
        "print(\"\\Answer: \", initial_response)"
      ],
      "metadata": {
        "id": "47W2LgaeSJlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Scenario No. 1 - Zero shot prompting"
      ],
      "metadata": {
        "id": "pzSo4U_Ie9oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup zero shot prompting\n",
        "initial_prompt = \"You are a network admin reviewing logs to identify hacking activity in the log\"\n",
        "\n",
        "# Dynamic row of logs retrieval (set to 75)\n",
        "log_text =\"\"\n",
        "for row in formatted_rows[:75]:\n",
        "    log_text += row + \" \"\n",
        "\n",
        "initial_prompt += \"\\nAnalyse this log entries. \" + log_text\n",
        "initial_prompt += \"\\nQuestion: What is likely be the hacking activity? Explain your answer.\"\n",
        "\n",
        "initial_model_inputs = tokenizer([initial_prompt], return_tensors=\"pt\").to(device)\n",
        "initial_model_outputs = model.generate(**initial_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "initial_response = tokenizer.batch_decode(initial_model_outputs)[0]\n",
        "print(\"\\Answer: \", initial_response)"
      ],
      "metadata": {
        "id": "beTSN9wRe8_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Scenario No. 2 - Few shot prompting"
      ],
      "metadata": {
        "id": "m8yoJ0_urzkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup few shot prompting\n",
        "initial_prompt = \"You are a network admin reviewing logs to identify hacking activity in the log\"\n",
        "\n",
        "# Dynamic row of logs retrieval (set to 75)\n",
        "log_text =\"\"\n",
        "for row in formatted_rows[:75]:\n",
        "    log_text += row + \" \"\n",
        "\n",
        "initial_prompt += \"\\nAnalyse this log entries. \" + log_text\n",
        "initial_prompt += \"\\nData Analysis: What does this specific DNS query suggest about network activity? Could it indicate a pattern of reconnaissance?\"\n",
        "initial_prompt += \"\\nScenario Evaluation: Imagine a sequence of DNS queries where each query targets a different IP address within the same subnet, all directed to port 53, occurring within minutes of each other. Assess the likelihood that this pattern represents network scanning or reconnaissance activity.\"\n",
        "initial_prompt += \"\\nImplications: Given multiple sequential DNS reverse lookup queries targeting each IP in a subnet without any operational justification, what security risks might this indicate?\"\n",
        "\n",
        "initial_model_inputs = tokenizer([initial_prompt], return_tensors=\"pt\").to(device)\n",
        "initial_model_outputs = model.generate(**initial_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "initial_response = tokenizer.batch_decode(initial_model_outputs)[0]\n",
        "print(\"\\Answer: \", initial_response)"
      ],
      "metadata": {
        "id": "TY0xL0XNr5mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Scenario No 3 - Chain of Thought Prompting"
      ],
      "metadata": {
        "id": "5tiu5mCgR1NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup chain of thought prompting\n",
        "initial_prompt = \"You are a network admin reviewing logs to identify hacking activity in the log\"\n",
        "initial_prompt = \"A log entry contains a reverse DNS lookup query noted as 'b'0.2.0.10.in-addr.arpa.'. Explain how to interpret this notation to understand the original IP address being queried.\"\n",
        "\n",
        "initial_model_inputs = tokenizer([initial_prompt], return_tensors=\"pt\").to(device)\n",
        "initial_model_outputs = model.generate(**initial_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "initial_response = tokenizer.batch_decode(initial_model_outputs)[0]\n",
        "print(\"\\nInitial answer: \", initial_response)\n",
        "\n",
        "second_prompt = initial_response + \"\\nGiven the previous understanding, Analyse the following entry. '2020-10-23 08:37:05 Src: 10.0.2.4, Dst: 10.0.2.1, Dst_Port: 53, Type: 12, Query: b'15.3.0.10.in-addr.arpa.', Code: 0'\"\n",
        "\n",
        "second_model_inputs = tokenizer([second_prompt], return_tensors=\"pt\").to(device)\n",
        "second_model_outputs = model.generate(**second_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "second_response = tokenizer.batch_decode(second_model_outputs)[0]\n",
        "print(\"\\nSecond answer: \", second_response)\n",
        "\n",
        "third_prompt = second_response + \"\\nScenario Evaluation: Imagine a sequence of DNS queries where each query targets a different IP address within the same subnet, all directed to port 53, occurring within minutes of each other. Assess the likelihood that this pattern represents network scanning or reconnaissance activity.\"\n",
        "third_prompt += \"\\nImplications: Given multiple sequential DNS reverse lookup queries targeting each IP in a subnet without any operational justification, what security risks might this indicate?\"\n",
        "\n",
        "third_model_inputs = tokenizer([third_prompt], return_tensors=\"pt\").to(device)\n",
        "third_model_outputs = model.generate(**third_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "third_response = tokenizer.batch_decode(third_model_outputs)[0]\n",
        "print(\"\\Third answer: \", third_response)\n",
        "\n",
        "log_text =\"\"\n",
        "for row in formatted_rows[:75]:\n",
        "    log_text += row + \" \"\n",
        "\n",
        "fourth_prompt = third_response + \"\\nAnalyse this log entries. \" + log_text\n",
        "fourth_prompt += \"\\nCould it be network scanning activity is happening? It is likely to be port scanning, host scanning or OS scanning? Explain your decision.\"\n",
        "\n",
        "fourth_model_inputs = tokenizer([fourth_prompt], return_tensors=\"pt\").to(device)\n",
        "fourth_model_outputs = model.generate(**fourth_model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "fourth_response = tokenizer.batch_decode(fourth_model_outputs)[0]\n",
        "print(\"\\Fourth answer: \", fourth_response)\n"
      ],
      "metadata": {
        "id": "aAa8MvZQBf8e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}